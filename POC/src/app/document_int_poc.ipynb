{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m poller \u001b[38;5;241m=\u001b[39m document_analysis_client\u001b[38;5;241m.\u001b[39mbegin_analyze_document_from_url(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprebuilt-layout\u001b[39m\u001b[38;5;124m\"\u001b[39m, formUrl)\n\u001b[0;32m     28\u001b[0m result \u001b[38;5;241m=\u001b[39m poller\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m---> 29\u001b[0m \u001b[43mprint_result\u001b[49m(result)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'print_result' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code sample shows Prebuilt Layout operations with the Azure Form Recognizer client library. \n",
    "The async versions of the samples require Python 3.6 or later.\n",
    "\n",
    "To learn more, please visit the documentation - Quickstart: Document Intelligence (formerly Form Recognizer) SDKs\n",
    "https://learn.microsoft.com/azure/ai-services/document-intelligence/quickstarts/get-started-sdks-rest-api?pivots=programming-language-python\n",
    "\"\"\"\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "\n",
    "\"\"\"\n",
    "Remember to remove the key from your code when you're done, and never post it publicly. For production, use\n",
    "secure methods to store and access your credentials. For more information, see \n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-security?tabs=command-line%2Ccsharp#environment-variables-and-application-configuration\n",
    "\"\"\"\n",
    "endpoint = \"https://hireboltai.cognitiveservices.azure.com/\"\n",
    "key = \"da710b81451f44d5a80890e97ad2aaed\"\n",
    "\n",
    "# sample document\n",
    "formUrl = \"https://hireme.blob.core.windows.net/cvs/Aditya Bhatt.pdf\"\n",
    "\n",
    "document_analysis_client = DocumentAnalysisClient(\n",
    "    endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    ")\n",
    "    \n",
    "poller = document_analysis_client.begin_analyze_document_from_url(\"prebuilt-layout\", formUrl)\n",
    "result = poller.result()\n",
    "print_result(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aditya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyresparser import ResumeParser\n",
    "import warnings\n",
    "data = ResumeParser(\"C:/Users/aditya/Desktop/2024/HireBolt.AI/POC/Aditya Bhatt CV.pdf\").get_extracted_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'Reporting', 'Excel', 'Flask', 'Key performance indicators', 'Ai', 'Data analysis', 'Datasets', 'Matplotlib', 'Github', 'Docker', 'Certification', 'Queries', 'Tensorflow', 'Healthcare', 'Logistics', 'Advertising', 'Training', 'Content', 'Presentations', 'Ggplot', 'Tableau', 'Python', 'Hypothesis', 'Coding', 'Software engineering', 'Real estate', 'Forecasting', 'Pyspark', 'Finance', 'Marketing', 'Architecture', 'Health', 'Consulting', 'Facebook', 'Database', 'Documentation', 'Pandas', 'Mysql', 'Sales', 'Engineering', 'Saas', 'Analysis', 'Pytorch', 'Sap', 'Etl', 'Budget', 'Analytics', 'Testing', 'Aws', 'Rest', 'Programming', 'Beautifulsoup', 'Interactive', 'Cash flow', 'Kpi', 'Operations', 'Statistics', 'Website', 'Sql', 'System', 'Machine learning', 'Metrics', 'Improvement', 'Presentation', 'Seaborn', 'Workflows', 'Modeling']\n"
     ]
    }
   ],
   "source": [
    "from pyresparser import ResumeParser\n",
    "\n",
    "def get_skills(filepath):\n",
    "    data = ResumeParser(filepath).get_extracted_data()\n",
    "    return data['skills']\n",
    "\n",
    "# Example usage\n",
    "skills = get_skills(\"C:/Users/aditya/Desktop/2024/HireBolt.AI/POC/Aditya Bhatt CV.pdf\")\n",
    "print(skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R',\n",
       " 'Reporting',\n",
       " 'Excel',\n",
       " 'Flask',\n",
       " 'Key performance indicators',\n",
       " 'Ai',\n",
       " 'Data analysis',\n",
       " 'Datasets',\n",
       " 'Matplotlib',\n",
       " 'Github',\n",
       " 'Docker',\n",
       " 'Certification',\n",
       " 'Queries',\n",
       " 'Tensorflow',\n",
       " 'Healthcare',\n",
       " 'Logistics',\n",
       " 'Advertising',\n",
       " 'Training',\n",
       " 'Content',\n",
       " 'Presentations',\n",
       " 'Ggplot',\n",
       " 'Tableau',\n",
       " 'Python',\n",
       " 'Hypothesis',\n",
       " 'Coding',\n",
       " 'Software engineering',\n",
       " 'Real estate',\n",
       " 'Forecasting',\n",
       " 'Pyspark',\n",
       " 'Finance',\n",
       " 'Marketing',\n",
       " 'Architecture',\n",
       " 'Health',\n",
       " 'Consulting',\n",
       " 'Facebook',\n",
       " 'Database',\n",
       " 'Documentation',\n",
       " 'Pandas',\n",
       " 'Mysql',\n",
       " 'Sales',\n",
       " 'Engineering',\n",
       " 'Saas',\n",
       " 'Analysis',\n",
       " 'Pytorch',\n",
       " 'Sap',\n",
       " 'Etl',\n",
       " 'Budget',\n",
       " 'Analytics',\n",
       " 'Testing',\n",
       " 'Aws',\n",
       " 'Rest',\n",
       " 'Programming',\n",
       " 'Beautifulsoup',\n",
       " 'Interactive',\n",
       " 'Cash flow',\n",
       " 'Kpi',\n",
       " 'Operations',\n",
       " 'Statistics',\n",
       " 'Website',\n",
       " 'Sql',\n",
       " 'System',\n",
       " 'Machine learning',\n",
       " 'Metrics',\n",
       " 'Improvement',\n",
       " 'Presentation',\n",
       " 'Seaborn',\n",
       " 'Workflows',\n",
       " 'Modeling']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aditya\\anaconda3\\envs\\steam1\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyresparser.resume_parser.ResumeParser object at 0x00000220AD037A30>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ResumeParser' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskills\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m \u001b[43mget_skills\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/aditya/Desktop/2024/HireBolt.AI/POC/Aditya Bhatt CV.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mget_skills\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m ResumeParser(filepath)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mskills\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ResumeParser' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def get_skills(filepath):\n",
    "    data = ResumeParser(filepath)\n",
    "    print(data)\n",
    "    return data['skills']\n",
    "\n",
    "get_skills(\"C:/Users/aditya/Desktop/2024/HireBolt.AI/POC/Aditya Bhatt CV.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aditya\\anaconda3\\envs\\steam1\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught an exception: AttributeError\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Configure logging to write to a text file\n",
    "logging.basicConfig(filename='error_log.txt', level=logging.ERROR)\n",
    "\n",
    "def get_skills(filepath):\n",
    "    try:\n",
    "        data = ResumeParser(filepath).get_extracted_data()\n",
    "        skills = data['skills'].lop\n",
    "        return skills\n",
    "    except Exception as e:\n",
    "        # Log the error to the console for debugging\n",
    "        print(f\"Caught an exception: {type(e).__name__}\")\n",
    "        \n",
    "        # Log the error to the text file\n",
    "        logging.error(f\"Error processing file '{filepath}': {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "skills = get_skills(\"C:/Users/aditya/Desktop/2024/HireBolt.AI/POC/Aditya Bhatt CV.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    print(\"open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "openai.api_key='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in string argument as parameter \n",
    "def comp(PROMPT, MaxToken=50, outputs=3): \n",
    "    # using OpenAI's Completion module that helps execute  \n",
    "    # any tasks involving text  \n",
    "    response = openai.Completion.create( \n",
    "        # model name used here is text-davinci-003 \n",
    "        # there are many other models available under the  \n",
    "        # umbrella of GPT-3 \n",
    "        model=\"text-davinci-003\", \n",
    "        # passing the user input  \n",
    "        prompt=PROMPT, \n",
    "        # generated output can have \"max_tokens\" number of tokens  \n",
    "        max_tokens=MaxToken, \n",
    "        # number of outputs generated in one call \n",
    "        n=outputs \n",
    "    ) \n",
    "    # creating a list to store all the outputs \n",
    "    output = list() \n",
    "    for k in response['choices']: \n",
    "        output.append(k['text'].strip()) \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m PROMPT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mCompute simialirity b/w \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcomp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMaxToken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mcomp\u001b[1;34m(PROMPT, MaxToken, outputs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomp\u001b[39m(PROMPT, MaxToken\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m): \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# using OpenAI's Completion module that helps execute  \u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# any tasks involving text  \u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# model name used here is text-davinci-003 \u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# there are many other models available under the  \u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# umbrella of GPT-3 \u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-davinci-003\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# passing the user input  \u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# generated output can have \"max_tokens\" number of tokens  \u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMaxToken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# number of outputs generated in one call \u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# creating a list to store all the outputs \u001b[39;00m\n\u001b[0;32m     18\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m() \n",
      "File \u001b[1;32mc:\\Users\\aditya\\anaconda3\\envs\\steam1\\lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"Compute simialirity b/w \"\"\"\n",
    "comp(PROMPT, MaxToken=3000, outputs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steam1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
