{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m poller \u001b[38;5;241m=\u001b[39m document_analysis_client\u001b[38;5;241m.\u001b[39mbegin_analyze_document_from_url(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprebuilt-layout\u001b[39m\u001b[38;5;124m\"\u001b[39m, formUrl)\n\u001b[0;32m     28\u001b[0m result \u001b[38;5;241m=\u001b[39m poller\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m---> 29\u001b[0m \u001b[43mprint_result\u001b[49m(result)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'print_result' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code sample shows Prebuilt Layout operations with the Azure Form Recognizer client library. \n",
    "The async versions of the samples require Python 3.6 or later.\n",
    "\n",
    "To learn more, please visit the documentation - Quickstart: Document Intelligence (formerly Form Recognizer) SDKs\n",
    "https://learn.microsoft.com/azure/ai-services/document-intelligence/quickstarts/get-started-sdks-rest-api?pivots=programming-language-python\n",
    "\"\"\"\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "\n",
    "\"\"\"\n",
    "Remember to remove the key from your code when you're done, and never post it publicly. For production, use\n",
    "secure methods to store and access your credentials. For more information, see \n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-security?tabs=command-line%2Ccsharp#environment-variables-and-application-configuration\n",
    "\"\"\"\n",
    "endpoint = \"https://hireboltai.cognitiveservices.azure.com/\"\n",
    "key = \"da710b81451f44d5a80890e97ad2aaed\"\n",
    "\n",
    "# sample document\n",
    "formUrl = \"https://hireme.blob.core.windows.net/cvs/Aditya Bhatt.pdf\"\n",
    "\n",
    "document_analysis_client = DocumentAnalysisClient(\n",
    "    endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    ")\n",
    "    \n",
    "poller = document_analysis_client.begin_analyze_document_from_url(\"prebuilt-layout\", formUrl)\n",
    "result = poller.result()\n",
    "print_result(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aditya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aditya\\anaconda3\\envs\\resume1\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from pyresparser import ResumeParser\n",
    "import warnings\n",
    "data = ResumeParser(\"C:/Users/aditya/Desktop/2024/HireBolt.AI/POC/Aditya Bhatt CV.pdf\").get_extracted_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Aditya Bhatt',\n",
       " 'email': 'adityabhatt19058568031.stats@rla.du.ac.in|Linkedin|Youtube|Github',\n",
       " 'mobile_number': '7303041453',\n",
       " 'skills': ['Budget',\n",
       "  'Healthcare',\n",
       "  'Forecasting',\n",
       "  'Pyspark',\n",
       "  'Health',\n",
       "  'Datasets',\n",
       "  'Tensorflow',\n",
       "  'Mysql',\n",
       "  'Flask',\n",
       "  'Metrics',\n",
       "  'Tableau',\n",
       "  'Facebook',\n",
       "  'Aws',\n",
       "  'Pandas',\n",
       "  'Excel',\n",
       "  'Workflows',\n",
       "  'Programming',\n",
       "  'Architecture',\n",
       "  'Modeling',\n",
       "  'Software engineering',\n",
       "  'Cash flow',\n",
       "  'Interactive',\n",
       "  'Seaborn',\n",
       "  'Reporting',\n",
       "  'Rest',\n",
       "  'R',\n",
       "  'Testing',\n",
       "  'Beautifulsoup',\n",
       "  'Queries',\n",
       "  'Training',\n",
       "  'Engineering',\n",
       "  'Advertising',\n",
       "  'Certification',\n",
       "  'Improvement',\n",
       "  'Finance',\n",
       "  'Real estate',\n",
       "  'Coding',\n",
       "  'Content',\n",
       "  'Statistics',\n",
       "  'Ggplot',\n",
       "  'Machine learning',\n",
       "  'Analytics',\n",
       "  'Etl',\n",
       "  'Sales',\n",
       "  'Github',\n",
       "  'Database',\n",
       "  'Docker',\n",
       "  'Website',\n",
       "  'Saas',\n",
       "  'Presentation',\n",
       "  'Matplotlib',\n",
       "  'Data analysis',\n",
       "  'Sql',\n",
       "  'Key performance indicators',\n",
       "  'Operations',\n",
       "  'System',\n",
       "  'Consulting',\n",
       "  'Documentation',\n",
       "  'Kpi',\n",
       "  'Analysis',\n",
       "  'Hypothesis',\n",
       "  'Logistics',\n",
       "  'Python',\n",
       "  'Marketing',\n",
       "  'Ai',\n",
       "  'Sap',\n",
       "  'Presentations',\n",
       "  'Pytorch'],\n",
       " 'college_name': None,\n",
       " 'degree': ['PG Diploma in Software Engineering for Data Science   '],\n",
       " 'designation': None,\n",
       " 'experience': ['help them make informed decisions.',\n",
       "  'Github | Demo',\n",
       "  '2.House Price Prediction (Real Estate):',\n",
       "  '. Spearheaded a comprehensive AI project, incorporating methodologies to ensure seamless data processing and analysis.',\n",
       "  'Utilizing  PySpark,  I  efficiently  transformed  and  cleansed  data,  while  Kafka  facilitated  data  ingestion  Explainable  AI',\n",
       "  'techniques ensured transparent model predictions.',\n",
       "  '. Successfully Dockerized the project, simplifying sharing and deployment, and maintained meticulous documentation to',\n",
       "  'enhance project understanding. Employing GitHub for version Control.',\n",
       "  '. Created AI System that helps us to predict property prices with an accuracy of 85%',\n",
       "  '. Used Pyspak, Kafka, Pandas, Pycaret, Docker, Modular coding, Github and Explainable AI.',\n",
       "  'Github |Technical Architecture',\n",
       "  '3.Let India Breathe (Environment Science):',\n",
       "  '. Leveraged PySpark on Azure Databricks for data science, analyzing and modeling PM 2.5 levels across 467 files stored on',\n",
       "  'Azure Blob Storage. Implemented MLFlow to deploy models, creating real-time REST endpoints. This interdisciplinary approach',\n",
       "  'aims to provide actionable insights for policymakers and communities, bridging the gap between environmental science and ai.',\n",
       "  'Demo',\n",
       "  'â€¢',\n",
       "  'Blogs:',\n",
       "  'Sensitivity and Specificity  Activation Function     Spatial Analytics Using Tableau  Tips & Tricks For Power BI'],\n",
       " 'company_names': ['Microsoft'],\n",
       " 'no_of_pages': 3,\n",
       " 'total_experience': 0.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steam1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
