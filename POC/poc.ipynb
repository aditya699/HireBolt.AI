{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "# This notebook is a part of understanding features for the application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting phone number from resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+91 7 303041453 \n",
      "No phone number found on page 2\n",
      "No phone number found on page 3\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# To get the phone number from resume\n",
    "def get_phone_number(filepath: str) -> str:\n",
    "    reader = PdfReader(filepath)\n",
    "    content_info = []\n",
    "    no_of_pages = len(reader.pages)\n",
    "    \n",
    "    for i in range(no_of_pages):\n",
    "        page = reader.pages[i]\n",
    "        content_info.append(page.extract_text())\n",
    "    \n",
    "\n",
    "        # Modified regex pattern to allow spaces in the phone number\n",
    "        pattern = r\"\\+91\\s?\\d\\s?\\d{9} | \\+91-d{10}\"\n",
    "        \n",
    "        # Using findall to get all matches in the content\n",
    "        results = re.findall(pattern, content_info[i])\n",
    "        \n",
    "        # Check if there are any matches\n",
    "        if results:\n",
    "            for match in results:\n",
    "                print(match)\n",
    "        else:\n",
    "            print(\"No phone number found on page\", i + 1)\n",
    "\n",
    "# Example usage\n",
    "get_phone_number(\"Aditya Bhatt CV.pdf\")\n",
    "\n",
    "#Still for safety the front end form will a phone number section since don't want to miss any thing due ai community guidelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adityabhatt19058568031.stats@rla.du.ac.in\n",
      "No phone number found on page 2\n",
      "No phone number found on page 3\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# To get the phone number from resume\n",
    "def get_phone_number(filepath: str) -> str:\n",
    "    reader = PdfReader(filepath)\n",
    "    content_info = []\n",
    "    no_of_pages = len(reader.pages)\n",
    "    \n",
    "    for i in range(no_of_pages):\n",
    "        page = reader.pages[i]\n",
    "        content_info.append(page.extract_text())\n",
    "    \n",
    "\n",
    "        # Modified regex pattern to allow spaces in the phone number\n",
    "        pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"\n",
    "        \n",
    "        # Using findall to get all matches in the content\n",
    "        results = re.findall(pattern, content_info[i])\n",
    "        \n",
    "        # Check if there are any matches\n",
    "        if results:\n",
    "            for match in results:\n",
    "                print(match)\n",
    "        else:\n",
    "            print(\"No phone number found on page\", i + 1)\n",
    "\n",
    "# Example usage\n",
    "get_phone_number(\"Aditya Bhatt CV.pdf\")\n",
    "\n",
    "#Still for safety the front end form will a phone number section since don't want to miss any thing due ai community guidelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" \\nAditya Bhatt   \\n+91 7 303041453  | adityabhatt19058568031.stats@rla.du.ac.in |Linkedin |Youtube |Github  \\nEDUCATIO N \\n \\nPG Diploma in Software Engineering for Data Science    (IIIT Hyderabad)                                              Jun 2022 - Dec 2023  \\nSecured 1st position in Car Price Prediction Hackathon  (AI). Portfolio 1       Portfolio 2      \\nBSC(H) Statistics                                                                 (Delhi University )               CGPA:9.14/10      Apr 2019 - Apr 202 2 \\nRelevant Project Work : Developed machine learning solution  for classification of people which would be used to allot social \\neconomic welfare to them, presented the same in Ramanujan College  and won Idea presentation Competition. Developed \\nDatabase and reporting solution for Placement Cell of the college.  \\n \\nEXPERIENCE  \\n \\nNeenopal - Business Analyst  July 2022 – Present  \\nglobal management consulting firm with a unique and specialized focus on Data Science  \\n• Worked with a logistics firm of Sri Lanka was involved in KPI Gathering, Data cleaning, Query (SQL & DAX) Development, \\nClient Handling and creating Power BI Dashboards concerning to logistics, Finance and Volume  department of the \\ncompany. This helped them to track, close tickets and optimize their operations . \\n• Worked with SAAS client to help them better manage their finances by developing dashboards for their income statement, \\nbalance sheet, and cash flow . The Power BI dashboards were customized to their specific business needs and \\npreferences, allowing them to track their financial metrics at a granular level and  take proactive actions to maximize \\ntheir profitability . \\n• Worked on Mockup.AI  , created a marketplace for HR, Finance  Based Dashboards in Power BI . \\n• Work ed on Sales Plug and play model helping companies track AOV , MAU, Product Penetration , Regional Analysis, Top N \\nSummary, Order Value Summary and Predicting Sales by integrating AI based time series forecasting (Using Prophet ) in \\nPower BI.  \\n• Creat ed business insights to optimize return on investment (ROI) by interpreting key trends in web, content, and advertising \\nanalytics, and using tools such as Tableau Prep, Tableau and Power BI  for data preparation and tracking performance. \\nAdditionally, identifying areas for improvement such as open rate, QUE, subscriptions, and cost control.  \\n• Worked on developing interactive dashboards for the GA4 playbook by using BigQuery and Power BI to track key performance \\nindicators such as daily active users, new users, repeat orders, and revenue. Additionally, conducted cohort analysis, heatmap \\nanalysis, and identified the best performing days and sources driving most of the website's traffic.  \\n• Worked with a logistics company used SQL,  Power BI & Power Query  analyzing 256 variables. Created a report to identify top \\nsales performers  helping them fastrack rewards to the best performers  \\n• Created and deployed a Power Apps -based application for comment capture and manager approval, seamlessly \\nintegrated with Power BI, Power automate  for data analysis, enabling streamlined workflows and data -driven insights.  \\nIntegrated a Power Virtual Agents  chatbot with the same for FAQ Section.  \\n• Orchestrated a comprehensive marketing performance analysis by aggregating data from Facebook, LinkedIn, Google Ads, \\nGoogle Analytics, and Klaviyo . Utilized BigQuery  to create views. The developed report, featuring visualizations and trend \\nanalyses, facilitated optimized budget allocation and contributed to enhanced marketing effectiveness.  \\n• Worked on creating  stored procedures and Power BI datasets  in healthcare analytics. Proficient in Power BI report creation, \\nwith active client management. Key contributor to strategic marketing plans and backend development  for a healthcare \\ncompany.  \\n\", \" \\nIneuron.AI  Sep 2021 –Dec 2021   \\nIneuron .AI started as a product development company, then launched its ed -tech division.  \\n•     Worked on SQL queries to find insights related to sales, creating dashboards using Tableau and Power BI  to visualize a \\ncompany's profit and student performance, mentoring data analysis students and machine learning participants , and \\ncreating statistical presentations using Python, R, and BI  tools for clients.  \\n \\nSKILLS AND PROFICIENCIES  \\n \\n• Programming (Python,  R, Pyspark ) \\n• Visualization  (Power BI, Tableau, Matplotlib, Seaborn, Plotly,  ggplot, Folium, Excel, R, Google Data Studio)  \\n• Machine Learning  (Supervised and Unsupervised Learning, ANN, CNN, Time Series Analysis, PyCaret, Pytorch, TensorFlow , \\nMLFlow , Azure ML Studio ) \\n• Statistics  (Descriptive Statistics, Inferential Statistics, Algebra, SPSS, Hypothesis Testing, Survey Sampling, Linear Modelling)  \\n• Database  (Azure Sql, MySQL, T -SQL, Postgre SQL,  SparkSQL,  MongoDB, Cassandra , MQL ) \\n• Deployment  (Flask, Streamlit, Heroku , Azure , AWS SageMaker , Docker ) \\n• Others  (Power Platform , TableauPrep , BeautifulSo up, SAP Crastal Report , Azure Data Factory ,Azure DataBricks ) \\n \\n• PERSONAL PROJECTS  / POC  \\n \\n1. Health Mate  (Heathtech) :  \\n  . Developed a web app to help users get health solutions such as medical insurance prediction, diabetes and stroke \\ndetection, and happiness index.    \\n. Utilized Python, Streamlit, Heroku, Cassandra (database), Flask, and Power BI for the development.  \\n. Implemented ETL, exploratory data analysis and visualizations, model training and deployed the app using Streamlit and \\nHeroku. The web app can help users get personalized health solutions, which would improve the user experience and \\nhelp them make informed decisions.  \\nGithub  | Demo  \\n2.House Price Prediction  (Real Estate) : \\n . Spearheaded a comprehensive AI project, incorporating methodologies to ensure seamless data processing and analysis. \\nUtilizing PySpark , I efficiently transformed and cleansed data, while Kafka facilitated data ingestion  Explainable AI  \\ntechniques ensured transparent model predictions.  \\n. Successfully Dockerized  the project, simplifying sharing and deployment, and maintained meticulous documentation to \\nenhance project understanding. Employing GitHub for version  Control.  \\n. Created AI System that helps us to predict property prices with an accuracy of 85%  \\n. Used Pyspak,  Kafka,  Pandas,  Pycaret,  Docker, Modular coding,  Github  and Explainable AI.  \\n           Github  |Technical Architecture  \\n3.Let India Breathe  (Environment Science ): \\n    . Leveraged PySpark on Azure Databricks  for data science, analyzing and modeling PM 2.5 levels across 467 files stored on \\nAzure Blob Storage. Implemented MLFlow  to deploy models, creating real -time REST endpoints. This interdisciplinary approach \\naims to provide actionable insights for policymakers and communities, bridging the gap between environmental science  and ai.  \\nDemo  \\n \", '•  Blogs:  \\n \\n         Sensitivity and Specificity   Activation Function      Spatial Analytics Using Tableau   Tips & Tricks For Power BI  \\n \\n• CERTIFICATIONS  / ACHIVEMENT S\\n \\n1.Worked in Analytics Vidhya summer internship , worked on lead scoring using machine learning and helped marketing \\nteam increase conversions by 23 -25% and developed a python module for students.  \\n2.Cleared  PL-900 Microsoft Certification  (Power Platform Fu ndamental s) \\n3.Cleared SQL Basic, Intermediate, Advanced  exam at HackerRank.  \\n4.Python,  SQL Gold Batch  at HackerRank.  \\n5. Made five submissions in Kaggle competitions ranked in top 40% in 3nd competition and ranked top 45% in 2nd \\ncompetition  \\n6. Awarded Employee of the Quarter for Q2 2023  \\n7.Cleared DP -100 (Microsoft Certified: Azure Data Scientist Associate)   ']\n"
     ]
    }
   ],
   "source": [
    "filepath=\"C:/Users/aditya/Desktop/2024/HireBolt.AI/POC/Aditya Bhatt CV.pdf\"\n",
    "reader = PdfReader(filepath)\n",
    "content_info = []\n",
    "no_of_pages = len(reader.pages)\n",
    "    \n",
    "for i in range(no_of_pages):\n",
    "    page = reader.pages[i]\n",
    "    content_info.append(page.extract_text())\n",
    "print(content_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
